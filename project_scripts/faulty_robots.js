const Faulty = `
<h2>Abstract</h2>
<p>
    This study replicates research on how errors in robots affect human trust and cooperation. We tested participants with a robot in either a correct or faulty mode. Findings showed no significant impact on trust or compliance, though there were slight deviations in responses between groups. More research with a larger sample size is recommended for better accuracy.
</p>


<h2>Introduction</h2>
<p>
    As robots become more common in various settings, including homes and workplaces, understanding trust in these robots is crucial. Trust affects how willing people are to follow robot instructions and collaborate with them. This study aims to explore factors influencing trust, particularly focusing on robot errors and their impact on human-robot interaction.
</p>

<h2>Related Work</h2>
<p>
    We reviewed foundational research on trust in automation, including:
    <ul>
        <li>Muir and Moray's work on trust and automation.</li>
        <li>Parasuraman et al.'s analysis of trust and user-friendly design.</li>
        <li>Bartneck et al.'s measurement tools for evaluating robots.</li>
        <li>Freedy et al.'s research on trust metrics in human-robot collaboration.</li>
    </ul>
    Additional papers cited by and citing our study provide further insights into factors affecting trust and interaction with robots.
</p>

<h2>Methods</h2>
<p>
    Participants interacted with the Fetch robot in two conditions: correct and faulty. The robotâ€™s behavior varied, and participants were asked to complete tasks while their trust and compliance were measured. The study used a between-participants design with a pre-questionnaire to gauge initial attitudes and moods.
</p>

<h2>Results</h2>
<p>
    The results showed no significant difference in trust levels or task compliance between the correct and faulty robot conditions. However, some deviation in responses was observed, indicating the need for further research with a larger sample.
</p>

<h2>Discussion</h2>
<p>
    Key insights include the need for a larger sample size to better understand trust dynamics. Future studies should explore hesitation times and analyze questionnaire responses more deeply. Participants' ability to recognize faults in the robot was notable and highlights the importance of realistic scenarios in testing.
</p>

<h2>Conclusion</h2>
<p>
    Our findings challenge the assumption that faulty behavior significantly affects trust. The study suggests that trust dynamics are complex and influenced by various factors, including context and individual differences. Continued research is essential for developing trustworthy robotic systems.
</p>
`;

export { Faulty };
